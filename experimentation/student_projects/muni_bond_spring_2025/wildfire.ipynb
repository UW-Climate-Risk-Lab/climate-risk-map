{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import xvec\n",
    "import os\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask\n",
    "\n",
    "from utils import download_and_read_fwi_data_for_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9096f",
   "metadata": {},
   "source": [
    "## Constants and Dask Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtbs_raster_data_dir = \"./data/mtbs_rasters\"\n",
    "mtbs_perimeter_data_path = \"./data/mtbs_perimeters/mtbs_perims_DD.shp\"\n",
    "eia_utility_service_areas_path = \"./data/eia_service_areas/Electric_Retail_Service_Territories.geojson\"\n",
    "fwi_variable = \"GPM.LATE.v5_FWI\"\n",
    "memory_per_worker = \"30GB\"\n",
    "n_workers = 6\n",
    "\n",
    "CRS = \"EPSG:4269\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4374f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    threads_per_worker=2,  \n",
    "    memory_limit=memory_per_worker  \n",
    ")\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554860a2",
   "metadata": {},
   "source": [
    "## Step 1.\n",
    "\n",
    "First, we read in the MTBS Wildfire and FWI data and package them in a list of dictionaries for processing. \n",
    "\n",
    "MTBS Data - https://www.mtbs.gov/direct-download\n",
    "\n",
    "FWI Data - https://portal.nccs.nasa.gov/datashare/GlobalFWI/v2.0/fwiCalcs.GEOS-5/Default/GPM.LATE.v5/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e86ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtbs_raster_files = os.listdir(mtbs_raster_data_dir)\n",
    "\n",
    "mtbs_gdf = gpd.read_file(mtbs_perimeter_data_path)\n",
    "\n",
    "input_data = []\n",
    "\n",
    "for file in mtbs_raster_files:\n",
    "    data_struct = {}\n",
    "\n",
    "    file_info = file[:-4].split(\"_\")\n",
    "    state = file_info[1]\n",
    "    year = int(file_info[2])\n",
    "\n",
    "    data_struct[\"state\"] = state\n",
    "    data_struct[\"year\"] = year\n",
    "\n",
    "    da_mtsb_raster = rioxarray.open_rasterio(f\"{mtbs_raster_data_dir}/{file}\")\n",
    "    da_mtsb_raster = da_mtsb_raster.rio.reproject(CRS)\n",
    "    # We filter here to include only values of meaningful fire severity\n",
    "    da_mtsb_raster = da_mtsb_raster.where((da_mtsb_raster >= 2) & (da_mtsb_raster < 5))\n",
    "    da_mtsb_raster.name = \"fire_severity\"\n",
    "    \n",
    "    # Read in historic fire perimeters\n",
    "    gdf_filtered = (mtbs_gdf.loc[(mtbs_gdf[\"Incid_Type\"]==\"Wildfire\") & (mtbs_gdf[\"Ig_Date\"].dt.year == data_struct[\"year\"]) & (mtbs_gdf[\"Event_ID\"].str.startswith(data_struct[\"state\"]))])\n",
    "    gdf_temp = gdf_filtered.set_index(\"Event_ID\")[[\"geometry\"]]\n",
    "    gdf_temp = gdf_temp.to_crs(da_mtsb_raster.spatial_ref.crs_wkt)\n",
    "    \n",
    "    # Read in NetCDF Fire Weather Index data from NASA. This download will take some time\n",
    "    ds_fwi = download_and_read_fwi_data_for_dates(gdf_filtered[\"Ig_Date\"])\n",
    "    ds_fwi = ds_fwi.rio.write_crs(\"EPSG:4326\")\n",
    "    ds_fwi = ds_fwi.rename({\"lat\": \"y\", \"lon\": \"x\", fwi_variable: \"fwi\"})\n",
    "    ds_fwi = ds_fwi.sel(x=slice(-125.4, -112.5), y=slice(32.4, 50.1))\n",
    "    da_fwi = ds_fwi[\"fwi\"].compute()\n",
    "    da_fwi_reproj = da_fwi.rio.reproject_match(da_mtsb_raster)\n",
    "    bounds = da_mtsb_raster.rio.bounds()\n",
    "    da_fwi_reproj_clipped = da_fwi_reproj.rio.clip_box(*bounds)\n",
    "\n",
    "    # Add copies of each processed input dataset\n",
    "    data_struct[\"da_fire_severity\"] = da_mtsb_raster.copy()\n",
    "    data_struct[\"gdf\"] = gdf_temp.copy()\n",
    "    data_struct[\"da_fwi\"] = da_fwi_reproj_clipped.copy()\n",
    "\n",
    "    print(f\"{state} {year} processed!\")\n",
    "    input_data.append(data_struct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5dd60d",
   "metadata": {},
   "source": [
    "## Step 2.\n",
    "\n",
    "We zonally aggregate the data to get the fire severity (mean, max) of each occurence of wildfire, as well as the Fire Weather Index (mean, max) measured at the ignition date of the fire. \n",
    "\n",
    "Note, we only have data for the ignition date. We do not know how long each fire burned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_severity_dfs = []\n",
    "\n",
    "for data in input_data:\n",
    "    da_name = data[\"da_fire_severity\"].name\n",
    "    da_temp = data[\"da_fire_severity\"].xvec.zonal_stats(\n",
    "        data[\"gdf\"].geometry,\n",
    "        x_coords=\"x\",\n",
    "        y_coords=\"y\",\n",
    "        stats=[\"mean\", \"max\"],\n",
    "        method=\"exactextract\",\n",
    "        index=True,\n",
    "    )\n",
    "    da_temp.name = da_name\n",
    "    df_temp = da_temp.to_dataframe().reset_index()\n",
    "\n",
    "    df_mean = df_temp.loc[df_temp[\"zonal_statistics\"]==\"mean\"]\n",
    "    df_mean = df_mean.rename(columns={da_name: da_name+\"_mean\"})\n",
    "\n",
    "    df_max = df_temp.loc[df_temp[\"zonal_statistics\"]==\"max\"]\n",
    "    df_max = df_max.rename(columns={da_name: da_name+\"_max\"})\n",
    "\n",
    "\n",
    "    df_temp =df_mean.merge(df_max, how=\"inner\", on=\"Event_ID\")[[\"Event_ID\", da_name+\"_mean\", da_name+\"_max\"]]\n",
    "    fire_severity_dfs.append(df_temp.copy())\n",
    "\n",
    "    state = data[\"state\"]\n",
    "    year = data[\"year\"]\n",
    "    print(f\"{state} {year} fire severity processed!\")\n",
    "\n",
    "fwi_dfs = []\n",
    "\n",
    "for data in input_data:\n",
    "    da_name = data[\"da_fwi\"].name\n",
    "    da_temp = data[\"da_fwi\"].xvec.zonal_stats(\n",
    "        data[\"gdf\"].geometry,\n",
    "        x_coords=\"x\",\n",
    "        y_coords=\"y\",\n",
    "        stats=[\"mean\", \"max\"],\n",
    "        method=\"exactextract\",\n",
    "        index=True,\n",
    "    )\n",
    "    da_temp.name = da_name\n",
    "    df_temp = da_temp.to_dataframe().reset_index()\n",
    "\n",
    "    df_mean = df_temp.loc[df_temp[\"zonal_statistics\"]==\"mean\"]\n",
    "    df_mean = df_mean.rename(columns={da_name: da_name+\"_mean\"})\n",
    "\n",
    "    df_max = df_temp.loc[df_temp[\"zonal_statistics\"]==\"max\"]\n",
    "    df_max = df_max.rename(columns={da_name: da_name+\"_max\"})\n",
    "\n",
    "    df_temp = pd.merge(df_max, df_mean, how=\"left\", on=[\"Event_ID\", \"time\"])[[\"Event_ID\", \"time\", da_name+\"_mean\", da_name+\"_max\"]]\n",
    "\n",
    "    fwi_dfs.append(df_temp.copy())\n",
    "\n",
    "    state = data[\"state\"]\n",
    "    year = data[\"year\"]\n",
    "    print(f\"{state} {year} FWI processed!\")\n",
    "\n",
    "fire_severity_df = pd.concat(fire_severity_dfs)\n",
    "fwi_df = pd.concat(fwi_dfs)\n",
    "fire_severity_df = fire_severity_df.drop_duplicates(subset=[\"Event_ID\"])\n",
    "fwi_df = fwi_df.drop_duplicates(subset=[\"Event_ID\", \"time\"])\n",
    "\n",
    "fire_df = fwi_df.merge(fire_severity_df, how='left', on=\"Event_ID\")\n",
    "\n",
    "mtbs_gdf_merged = mtbs_gdf.merge(fire_df, how='left', left_on=[\"Event_ID\", \"Ig_Date\"], right_on=[\"Event_ID\", \"time\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a53f5",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "We read in the utility service area data and join the fire metrics with it. Our final output contains each utility service area for Oregon, California, and Washington and every wildfire that occured in their service area. The fire is quantified by its severity and fire weather index value. \n",
    "\n",
    "EIA Utility Service Area Data - https://atlas.eia.gov/maps/geoplatform::electric-retail-service-territories-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_areas_raw = gpd.read_file(eia_utility_service_areas_path)\n",
    "service_areas = service_areas_raw.to_crs(CRS)\n",
    "\n",
    "mtbs_gdf_final = mtbs_gdf_merged[[\"Event_ID\", \"Ig_Date\", \"BurnBndAc\", \"fire_severity_mean\", \"fire_severity_max\", \"fwi_mean\", \"fwi_max\", \"geometry\"]]\n",
    "\n",
    "df_final = service_areas.sjoin(mtbs_gdf_final)\n",
    "df_final = df_final.drop(columns=[\"geometry\", \"index_right\"])\n",
    "df_final = df_final.dropna(subset=\"fire_severity_mean\")\n",
    "df_final = df_final.rename({\"Event_ID\": \"Fire_ID\"})\n",
    "df_final = df_final.sort_values(by=[\"ID\", \"Ig_Date\"])\n",
    "\n",
    "df_final.to_csv(\"utility_service_area_fire_metrics.csv.gz\", index=False, compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
