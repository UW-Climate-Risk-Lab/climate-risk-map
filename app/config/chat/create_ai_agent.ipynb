{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to be an initial setup of an AI agent in AWS Bedrock. This allows for code interpretation and passing in files, which makes it ideal for an autonomous data analyst. We use Claude 3.5 Sonnet as the foundation model. This agent will be used in the user interface of the mapping application.\n",
    "\n",
    "Based on AWS example: https://github.com/build-on-aws/agents-for-amazon-bedrock-sample-feature-notebooks/blob/main/notebooks/preview-agent-code-interpreter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "This first code block is to be run once to initialize the agent on AWS Bedrock. This includes the appropriate IAM role and policy and instruction set for agent. We choose us-west-2 because that is the region that claude 3.5 is available to use code interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = boto3.client('sts')\n",
    "caller_identity = sts.get_caller_identity()\n",
    "ACCOUNT_ID = str(caller_identity['Account'])\n",
    "\n",
    "REGION_NAME = 'us-west-2'\n",
    "FOUNDATIONAL_MODEL = 'amazon.nova-pro-v1:0'\n",
    "INFERENCE_PROFILE = f\"us.{FOUNDATIONAL_MODEL}\"\n",
    "AGENT_NAME = f'climate-risk-map-ai-agent-{FOUNDATIONAL_MODEL.replace(\":\", \"_\").replace(\".\", \"_\")}'\n",
    "IAM_ROLE_NAME = f'{AGENT_NAME}-role'[0:63]\n",
    "MODEL_POLICY_NAME = f'{AGENT_NAME}-model-policy'\n",
    "INFERENCE_POLICY_NAME = f'{AGENT_NAME}-inference-policy'\n",
    "TRUST_POLICY = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": ACCOUNT_ID\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": f\"arn:aws:bedrock:us-west-2:{ACCOUNT_ID}:agent/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "MODEL_POLICY = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:InvokeModel\",\n",
    "                \"bedrock:InvokeModelWithResponseStream\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:us-west-2::foundation-model/{FOUNDATIONAL_MODEL}\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "INFERENCE_PROFILE_POLICY = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:InvokeModel\",\n",
    "                \"bedrock:InvokeModelWithResponseStream\",\n",
    "                \"bedrock:GetInferenceProfile\",\n",
    "                \"bedrock:GetFoundationModel\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:us-west-2:{ACCOUNT_ID}:inference-profile/{INFERENCE_PROFILE}\",\n",
    "                f\"arn:aws:bedrock:*::foundation-model/{FOUNDATIONAL_MODEL}\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "You are an advanced AI instructor specializing in physical climate risk analysis for infrastructure assets, platform, operating within an application that visualizes asset-level vulnerability.\n",
    "Your analysis must be educational, contextual, insightful, and framed to highlight potential financial implications of the identified risks.\n",
    "\n",
    "**Core Analysis Directives & Metrics:**\n",
    "* **Synthesize Three Key Metrics:** Your primary task is to analyze risk using the interplay of these three metrics:\n",
    "    1.  `ensemble_mean`: **Projected FWI (Future Fire Weather Intensity)**. Interpret using the FWI scale provided below. This reflects *how intense* fire weather could be.\n",
    "    2.  `ensemble_mean_historic_baseline`: **Historical FWI (Past Fire Weather Intensity)**. Use this primarily to calculate and emphasize the **change** or **increase** in future FWI potential compared to the past (`ensemble_mean` - `ensemble_mean_historic_baseline`). A large increase signifies significantly worsening fire weather conditions.\n",
    "    3.  `burn_probability`: **Annual Burn Probability (Likelihood of Burning)**. Interpret this as the statistical likelihood (e.g., a value of 0.02 means a 2% chance per year) of that specific location burning based on landscape/fuel conditions circa 2021. This reflects *how likely* a fire is at that location.\n",
    "* **Financial Risk Framing:** Explicitly connect the physical risk analysis to potential financial implications. You don't have dollar figures, so use qualitative framing. Examples:\n",
    "    * \"Assets facing a significant *increase* in FWI combined with a non-negligible `burn_probability` represent heightened potential for operational disruptions, costly repairs, and associated financial losses.\"\n",
    "    * \"The higher `burn_probability` in Area Y suggests a greater likelihood of wildfire occurrence, potentially leading to increased insurance premiums or mitigation costs for assets located there, especially those critical assets like high-voltage lines.\"\n",
    "    * \"Understanding this combined risk profile (intensity increase + likelihood) is crucial for financial planning, risk mitigation investment decisions, and asset management strategies.\"\n",
    "* **Context is Crucial:**\n",
    "    * Always interpret `ensemble_mean` (Projected FWI) using the FWI scale.\n",
    "    * Always highlight the *change* from `ensemble_mean_historic_baseline`.\n",
    "    * Explain `burn_probability` clearly (e.g., \"a 1.5% annual likelihood of burning\").\n",
    "    * Mention metric limitations: FWI is weather-only (no fuel/topo); Burn Probability is based on ~2021 landscape conditions and simulations.\n",
    "* **Specificity Wins:** Drill down into asset specifics using `osm_subtype`, `county`, `city`, and details like `line;voltage`, `line;name`, `plant;name`, `plant:source`. High-voltage lines or critical plants deserve special mention.\n",
    "* **Comparative Insights:** Compare risks across asset subtypes, counties, or highlight assets with the most concerning *combined* risk profile (e.g., high FWI increase AND high burn probability).\n",
    "\n",
    "**\"Wow\" Factors & Engagement:**\n",
    "* **Pinpoint Combined High Risk:** Proactively identify the asset(s) with the most concerning *combination* of risk factors (e.g., highest FWI *increase* AND highest `burn_probability`). Describe why this combination is particularly noteworthy from a risk management perspective.\n",
    "* **Highlight Change:** Emphasize the *magnitude of change* from the historical baseline FWI. Statements like \"This location is projected to see fire weather intensity potential *increase by X points* compared to the historical average...\" are impactful.\n",
    "* **Narrative Flow:** Weave the three metrics into a compelling narrative. Start with the future intensity (FWI), compare it to the past (baseline change), and then layer in the likelihood (burn probability).\n",
    "* **Actionable Framing:** Conclude analyses with statements that guide user thinking towards action or further investigation, linking back to financial/operational stability.\n",
    "* **Suggest Follow-ups:** ALWAYS suggest 2-3 distinct, relevant follow-up questions based on the new metrics. Examples:\n",
    "    * \"Would you like to see which assets have the largest *increase* in FWI compared to the baseline?\"\n",
    "    * \"Shall I list assets with a Burn Probability higher than [threshold, e.g., 1%]?\"\n",
    "    * \"Can we compare the combined risk profile of [Substations] vs. [Power Lines] in [County X]?\"\n",
    "\n",
    "**Climate & Wildfire Knowledge:**\n",
    "* **FWI (Fire Weather Index):** (Keep existing description)\n",
    "* **FWI Scale:**\n",
    "    * 0-5: Very low\n",
    "    * 5-10: Low\n",
    "    * 10-20: Moderate\n",
    "    * 20-30: High\n",
    "    * 30+: Extreme\n",
    "* **FWI Limitations:** Does not include fuel loads or topography.\n",
    "* **Burn Probability (BP):** Represents the *annual likelihood* of a 500m location burning based on simulations calibrated to 2006-2020 fire history and landscape conditions circa 2021 (fuels, vegetation). It accounts for how fire might spread, including 'oozing' into adjacent developed areas up to ~1 mile. Does not account for fuel changes post-2021. Higher values indicate greater likelihood of fire occurrence.\n",
    "* **SSP Scenarios:** (Keep existing description, noting SSP5-8.5 is in use).\n",
    "\n",
    "**Code Execution:**\n",
    "* **Mandatory Use:** Always use the Python environment for calculations (averages, max/min, differences, counts, filtering, sorting) and specific data lookups from the provided 'data.csv'.\n",
    "* **Integration:** Seamlessly integrate code results into your narrative. Present tables clearly if generated. Calculate the FWI change (`ensemble_mean` - `ensemble_mean_historic_baseline`) when relevant.\n",
    "\n",
    "**Output Format:**\n",
    "* Use MARKDOWN.\n",
    "* `##` for main titles, `###`/`####` for sub-sections. NO `#` headings.\n",
    "* Use bullet points and **bold text** for key metrics, asset names/IDs, location names, and significant findings (especially the FWI *change* and *combined* risk insights).\n",
    "* Prioritize the most impactful combined risk insights for the demo. Be concise yet thorough.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bedrock_agent = boto3.client(service_name = 'bedrock-agent', region_name = REGION_NAME)\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "print(\"Creating the IAM policy and role...\")\n",
    "\n",
    "# Create IAM role and attach policy\n",
    "\n",
    "try:\n",
    "    role = iam.create_role(\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument = json.dumps(TRUST_POLICY)\n",
    "    )\n",
    "\n",
    "    iam.put_role_policy(\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        PolicyName = MODEL_POLICY_NAME,\n",
    "        PolicyDocument = json.dumps(MODEL_POLICY)\n",
    "    )\n",
    "\n",
    "    iam.put_role_policy(\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        PolicyName = INFERENCE_POLICY_NAME,\n",
    "        PolicyDocument = json.dumps(INFERENCE_PROFILE_POLICY)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"{str(e)}\")\n",
    "    role = iam.get_role(RoleName=IAM_ROLE_NAME)\n",
    "\n",
    "roleArn = role['Role']['Arn']\n",
    "\n",
    "# --- ADD DELAY ---\n",
    "print(\"Waiting for IAM propagation...\")\n",
    "time.sleep(2) # Wait for 15 seconds\n",
    "# --- END DELAY ---\n",
    "\n",
    "\n",
    "print(f\"IAM Role: {roleArn[:13]}{'*' * 12}{roleArn[25:]}\")\n",
    "\n",
    "print(\"Creating the agent...\")\n",
    "\n",
    "# Create the Bedrock Agent\n",
    "response = bedrock_agent.create_agent(\n",
    "    agentName=AGENT_NAME,\n",
    "    foundationModel=INFERENCE_PROFILE,\n",
    "    instruction=INSTRUCTION,\n",
    "    agentResourceRoleArn=roleArn,\n",
    ")\n",
    "\n",
    "agentId = response['agent']['agentId']\n",
    "\n",
    "print(\"Waiting for agent status of 'NOT_PREPARED'...\")\n",
    "# Wait for agent to reach 'NOT_PREPARED' status\n",
    "agentStatus = ''\n",
    "while agentStatus != 'NOT_PREPARED':\n",
    "    response = bedrock_agent.get_agent(\n",
    "        agentId=agentId\n",
    "    )\n",
    "    agentStatus = response['agent']['agentStatus']\n",
    "    print(f\"Agent status: {agentStatus}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "######################################### Configure code interpreter for the agent\n",
    "response = bedrock_agent.create_agent_action_group(\n",
    "    \n",
    "    actionGroupName='CodeInterpreterAction',\n",
    "    actionGroupState='ENABLED',\n",
    "    agentId=agentId,\n",
    "    agentVersion='DRAFT',\n",
    "    parentActionGroupSignature='AMAZON.CodeInterpreter' # <-  To allow your agent to generate, \n",
    "                                                        #     run, and troubleshoot code when trying \n",
    "                                                        #     to complete a task, set this field to \n",
    "                                                        #     AMAZON.CodeInterpreter. \n",
    "                                                        #     You must leave the `description`, `apiSchema`, \n",
    "                                                        #     and `actionGroupExecutor` fields blank for \n",
    "                                                        #     this action group.\n",
    ")\n",
    "\n",
    "actionGroupId = response['agentActionGroup']['actionGroupId']\n",
    "\n",
    "print(\"Waiting for action group status of 'ENABLED'...\")\n",
    "\n",
    "# Wait for action group to reach 'ENABLED' status\n",
    "actionGroupStatus = ''\n",
    "while actionGroupStatus != 'ENABLED':\n",
    "    response = bedrock_agent.get_agent_action_group(\n",
    "        agentId=agentId,\n",
    "        actionGroupId=actionGroupId,\n",
    "        agentVersion='DRAFT'\n",
    "    )\n",
    "    actionGroupStatus = response['agentActionGroup']['actionGroupState']\n",
    "    print(f\"Action Group status: {actionGroupStatus}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Preparing the agent...\")\n",
    "\n",
    "# Prepare the agent for use\n",
    "response = bedrock_agent.prepare_agent(\n",
    "    agentId=agentId\n",
    ")\n",
    "\n",
    "print(\"Waiting for agent status of 'PREPARED'...\")\n",
    "\n",
    "# Wait for agent to reach 'PREPARED' status\n",
    "agentStatus = ''\n",
    "while agentStatus != 'PREPARED':\n",
    "    response = bedrock_agent.get_agent(\n",
    "        agentId=agentId\n",
    "    )\n",
    "    agentStatus = response['agent']['agentStatus']\n",
    "    print(f\"Agent status: {agentStatus}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Create an alias for the agent\n",
    "response = bedrock_agent.create_agent_alias(\n",
    "    agentAliasName='test',\n",
    "    agentId=agentId\n",
    ")\n",
    "\n",
    "agentAliasId = response['agentAlias']['agentAliasId']\n",
    "\n",
    "# Wait for agent alias to be prepared\n",
    "agentAliasStatus = ''\n",
    "while agentAliasStatus != 'PREPARED':\n",
    "    response = bedrock_agent.get_agent_alias(\n",
    "        agentId=agentId,\n",
    "        agentAliasId=agentAliasId\n",
    "    )\n",
    "    agentAliasStatus = response['agentAlias']['agentAliasStatus']\n",
    "    print(f\"Agent alias status: {agentAliasStatus}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "print('Done.\\n')\n",
    "\n",
    "print(f\"agentId: {agentId}, agentAliasId: {agentAliasId}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utility Functions\n",
    "\n",
    "These functions are useful to use when interacting with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDROCK_AGENT_RUNTIME = boto3.client(service_name = 'bedrock-agent-runtime', region_name = REGION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_bytes(file_path):\n",
    "    \"\"\"Reads a CSV file and returns its content as bytes.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The content of the CSV file as bytes, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            csv_bytes = file.read()\n",
    "            return csv_bytes\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred: {e}\")\n",
    "         return None\n",
    "\n",
    "def invoke(inputText, sessionId, file_path, showTrace=False, endSession=False):\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Invoke the Agent - Sends a prompt for the agent to process and respond to.\n",
    "        response = BEDROCK_AGENT_RUNTIME.invoke_agent(\n",
    "            agentAliasId=agentAliasId,   # (string) – [REQUIRED] The alias of the agent to use.\n",
    "            agentId=agentId,             # (string) – [REQUIRED] The unique identifier of the agent to use.\n",
    "            sessionId=sessionId,         # (string) – [REQUIRED] The unique identifier of the session. Use the same value across requests to continue the same conversation.\n",
    "            inputText=inputText,         # (string) - The prompt text to send the agent.\n",
    "            endSession=endSession,       # (boolean) – Specifies whether to end the session with the agent or not.\n",
    "            enableTrace=True,            # (boolean) – Specifies whether to turn on the trace or not to track the agent's reasoning process.\n",
    "            sessionState = {\n",
    "                \"files\": [\n",
    "                    {\n",
    "                        \"name\": \"test_data.json\",\n",
    "                        \"source\": {\n",
    "                            \"byteContent\": {\n",
    "                                \"data\": read_csv_bytes(file_path=file_path),\n",
    "                                \"mediaType\": \"text/csv\"\n",
    "                            },\n",
    "                            \"sourceType\": \"BYTE_CONTENT\"\n",
    "                       },\n",
    "                        \"useCase\": \"CODE_INTERPRETER\"\n",
    "                    }\n",
    "                ]\n",
    "             }\n",
    "        )\n",
    "\n",
    "        # The response of this operation contains an EventStream member. \n",
    "        event_stream = response[\"completion\"]\n",
    "\n",
    "        # When iterated the EventStream will yield events.\n",
    "        for event in event_stream:\n",
    "\n",
    "            # chunk contains a part of an agent response\n",
    "            if 'chunk' in event:\n",
    "                chunk = event['chunk']\n",
    "                if 'bytes' in chunk:\n",
    "                    text = chunk['bytes'].decode('utf-8')\n",
    "                    print(f\"Chunk: {text}\")\n",
    "                else:\n",
    "                    print(\"Chunk doesn't contain 'bytes'\")\n",
    "\n",
    "            # files contains intermediate response for code interpreter if any files have been generated.\n",
    "            if 'files' in event:\n",
    "                files = event['files']['files']\n",
    "                for file in files:\n",
    "                    name = file['name']\n",
    "                    type = file['type']\n",
    "                    bytes_data = file['bytes']\n",
    "                    \n",
    "                    # It the file is a PNG image then we can display it...\n",
    "                    if type == 'image/png':\n",
    "                        # Display PNG image using Matplotlib\n",
    "                        img = plt.imread(io.BytesIO(bytes_data))\n",
    "                        plt.figure(figsize=(10, 10))\n",
    "                        plt.imshow(img)\n",
    "                        plt.axis('off')\n",
    "                        plt.title(name)\n",
    "                        plt.show()\n",
    "                        plt.close()\n",
    "                        \n",
    "                    # If the file is NOT a PNG then we save it to disk...\n",
    "                    else:\n",
    "                        # Save other file types to local disk\n",
    "                        with open(name, 'wb') as f:\n",
    "                            f.write(bytes_data)\n",
    "                        print(f\"File '{name}' saved to disk.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDROCK_AGENT_RUNTIME = boto3.client(service_name = 'bedrock-agent-runtime', region_name = \"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDROCK_AGENT_RUNTIME.list_sessions(maxResults=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scenariomip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
